{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos el dataset en el cual ya hemos trabajado las nuevas variables y caracteristicas.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "#!pip install --upgrade lightgbm\n",
    "#!pip install category_encoders\n",
    "#!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos los datasets de cada mes que ya hemos balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'final_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset para 2019-01 cargado desde: final_datasets\\resampled_data_2019_01.csv\n",
      "Dataset para 2019-02 cargado desde: final_datasets\\resampled_data_2019_02.csv\n",
      "Dataset para 2019-03 cargado desde: final_datasets\\resampled_data_2019_03.csv\n",
      "Dataset para 2019-04 cargado desde: final_datasets\\resampled_data_2019_04.csv\n",
      "Dataset para 2019-05 cargado desde: final_datasets\\resampled_data_2019_05.csv\n",
      "Dataset para 2019-06 cargado desde: final_datasets\\resampled_data_2019_06.csv\n",
      "Dataset para 2019-07 cargado desde: final_datasets\\resampled_data_2019_07.csv\n",
      "Dataset para 2019-08 cargado desde: final_datasets\\resampled_data_2019_08.csv\n",
      "Dataset para 2019-09 cargado desde: final_datasets\\resampled_data_2019_09.csv\n",
      "Dataset para 2019-10 cargado desde: final_datasets\\resampled_data_2019_10.csv\n",
      "Dataset para 2019-11 cargado desde: final_datasets\\resampled_data_2019_11.csv\n",
      "Dataset para 2019-12 cargado desde: final_datasets\\resampled_data_2019_12.csv\n",
      "Dataset para 2020-01 cargado desde: final_datasets\\resampled_data_2020_01.csv\n",
      "Dataset para 2020-02 cargado desde: final_datasets\\resampled_data_2020_02.csv\n",
      "Dataset para 2020-03 cargado desde: final_datasets\\resampled_data_2020_03.csv\n",
      "Dataset para 2020-04 cargado desde: final_datasets\\resampled_data_2020_04.csv\n",
      "Dataset para 2020-05 cargado desde: final_datasets\\resampled_data_2020_05.csv\n",
      "Dataset para 2020-06 cargado desde: final_datasets\\resampled_data_2020_06.csv\n",
      "Dataset para 2020-07 cargado desde: final_datasets\\resampled_data_2020_07.csv\n",
      "Dataset para 2020-08 cargado desde: final_datasets\\resampled_data_2020_08.csv\n",
      "Dataset para 2020-09 cargado desde: final_datasets\\resampled_data_2020_09.csv\n",
      "Dataset para 2020-10 cargado desde: final_datasets\\resampled_data_2020_10.csv\n",
      "Dataset para 2020-11 cargado desde: final_datasets\\resampled_data_2020_11.csv\n",
      "Dataset para 2020-12 cargado desde: final_datasets\\resampled_data_2020_12.csv\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los datasets\n",
    "monthly_datasets = {}\n",
    "\n",
    "# Listar todos los archivos en el directorio\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.startswith('resampled_data_') and file_name.endswith('.csv'):\n",
    "        # Construir el path completo del archivo\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "\n",
    "        # Extraer la fecha del nombre del archivo\n",
    "        date_str = file_name[len('resampled_data_'):-4]\n",
    "        month = pd.to_datetime(date_str, format='%Y_%m')\n",
    "\n",
    "        # Cargar el dataset\n",
    "        monthly_datasets[month] = pd.read_csv(file_path)\n",
    "        print(f\"Dataset para {month.strftime('%Y-%m')} cargado desde: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a separar el dataset en 80% entrenamiento y 20% validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento con LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento individual de los meses (no incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1abbd4c4f70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no queremos llenar el output con imagenes entonces\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con datos de: 2019-01-01 00:00:00\n",
      "Entrenando con datos de: 2019-02-01 00:00:00\n",
      "Entrenando con datos de: 2019-03-01 00:00:00\n",
      "Entrenando con datos de: 2019-04-01 00:00:00\n",
      "Entrenando con datos de: 2019-05-01 00:00:00\n",
      "Entrenando con datos de: 2019-06-01 00:00:00\n",
      "Entrenando con datos de: 2019-07-01 00:00:00\n",
      "Entrenando con datos de: 2019-08-01 00:00:00\n",
      "Entrenando con datos de: 2019-09-01 00:00:00\n",
      "Entrenando con datos de: 2019-10-01 00:00:00\n",
      "Entrenando con datos de: 2019-11-01 00:00:00\n",
      "Entrenando con datos de: 2019-12-01 00:00:00\n",
      "Entrenando con datos de: 2020-01-01 00:00:00\n",
      "Entrenando con datos de: 2020-02-01 00:00:00\n",
      "Entrenando con datos de: 2020-03-01 00:00:00\n",
      "Entrenando con datos de: 2020-04-01 00:00:00\n",
      "Entrenando con datos de: 2020-05-01 00:00:00\n",
      "Entrenando con datos de: 2020-06-01 00:00:00\n",
      "Entrenando con datos de: 2020-07-01 00:00:00\n",
      "Entrenando con datos de: 2020-08-01 00:00:00\n",
      "Entrenando con datos de: 2020-09-01 00:00:00\n",
      "Entrenando con datos de: 2020-10-01 00:00:00\n",
      "Entrenando con datos de: 2020-11-01 00:00:00\n",
      "Entrenando con datos de: 2020-12-01 00:00:00\n",
      "Revisa las carpetas dentro de 'LGBM_noIncrements_performance' para ver el desempeño de los modelos.\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de LightGBM\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "lgb_model = None\n",
    "folder_path = 'LGBM_noIncrements_performance'\n",
    "\n",
    "# Subcarpetas\n",
    "roc_folder = os.path.join(folder_path, 'roc_curves')\n",
    "conf_matrix_folder = os.path.join(folder_path, 'conf_matrices')\n",
    "metrics_folder = os.path.join(folder_path, 'metrics_texts')\n",
    "\n",
    "# Asegurarse de que las carpetas estén limpias\n",
    "for path in [folder_path, roc_folder, conf_matrix_folder, metrics_folder]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Abrir archivo de texto para escribir las métricas\n",
    "metrics_file_path = os.path.join(metrics_folder, 'model_metrics.txt')\n",
    "with open(metrics_file_path, 'w') as metrics_file:\n",
    "    # Iterar sobre cada segmento mensual y entrenar modelos\n",
    "    for name, month_data in monthly_datasets.items():\n",
    "        print(f\"Entrenando con datos de: {name}\")\n",
    "\n",
    "        # Dividir los datos en entrenamiento y validación\n",
    "        X = month_data.drop(['is_fraud'], axis=1)\n",
    "        y = month_data['is_fraud']\n",
    "        X_train_month, X_val_month, y_train_month, y_val_month = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        train_data_month = lgb.Dataset(X_train_month, label=y_train_month)\n",
    "        valid_data_month = lgb.Dataset(X_val_month, label=y_val_month)\n",
    "\n",
    "        # Entrenamiento con validación\n",
    "        lgb_model = lgb.train(\n",
    "            params,\n",
    "            train_data_month,\n",
    "            num_boost_round=100,\n",
    "            valid_sets=[valid_data_month],\n",
    "            valid_names=['validation']\n",
    "        )\n",
    "\n",
    "        # Predecir en el conjunto de validación\n",
    "        y_pred = lgb_model.predict(X_val_month, num_iteration=lgb_model.best_iteration)\n",
    "        y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "        # Calcular métricas\n",
    "        f1 = f1_score(y_val_month, y_pred_binary)\n",
    "        accuracy = accuracy_score(y_val_month, y_pred_binary)\n",
    "        precision = precision_score(y_val_month, y_pred_binary)\n",
    "        recall = recall_score(y_val_month, y_pred_binary)\n",
    "        cm = confusion_matrix(y_val_month, y_pred_binary)\n",
    "\n",
    "        # Graficar ROC\n",
    "        fpr, tpr, _ = roc_curve(y_val_month, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for {name.strftime(\"%B %Y\")}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(roc_folder, f'roc_curve_{name.strftime(\"%Y_%m\")}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Graficar matriz de confusión\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f'Confusion Matrix for {name.strftime(\"%B %Y\")}')\n",
    "        plt.savefig(os.path.join(conf_matrix_folder, f'conf_matrix_{name.strftime(\"%Y_%m\")}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Escribir métricas al archivo de texto\n",
    "        metrics_file.write(f\"Metrics for {name.strftime('%B %Y')}:\\n\")\n",
    "        metrics_file.write(f\"F1 Score: {f1:.2f}\\n\")\n",
    "        metrics_file.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "        metrics_file.write(f\"Precision: {precision:.2f}\\n\")\n",
    "        metrics_file.write(f\"Recall: {recall:.2f}\\n\")\n",
    "        metrics_file.write(f\"Confusion Matrix:\\n{cm}\\n\\n\")\n",
    "\n",
    "print(\"Revisa las carpetas dentro de 'LGBM_noIncrements_performance' para ver el desempeño de los modelos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con datos de: 2019-01-01 00:00:00\n",
      "Entrenando con datos de: 2019-02-01 00:00:00\n",
      "Entrenando con datos de: 2019-03-01 00:00:00\n",
      "Entrenando con datos de: 2019-04-01 00:00:00\n",
      "Entrenando con datos de: 2019-05-01 00:00:00\n",
      "Entrenando con datos de: 2019-06-01 00:00:00\n",
      "Entrenando con datos de: 2019-07-01 00:00:00\n",
      "Entrenando con datos de: 2019-08-01 00:00:00\n",
      "Entrenando con datos de: 2019-09-01 00:00:00\n",
      "Entrenando con datos de: 2019-10-01 00:00:00\n",
      "Entrenando con datos de: 2019-11-01 00:00:00\n",
      "Entrenando con datos de: 2019-12-01 00:00:00\n",
      "Entrenando con datos de: 2020-01-01 00:00:00\n",
      "Entrenando con datos de: 2020-02-01 00:00:00\n",
      "Entrenando con datos de: 2020-03-01 00:00:00\n",
      "Entrenando con datos de: 2020-04-01 00:00:00\n",
      "Entrenando con datos de: 2020-05-01 00:00:00\n",
      "Entrenando con datos de: 2020-06-01 00:00:00\n",
      "Entrenando con datos de: 2020-07-01 00:00:00\n",
      "Entrenando con datos de: 2020-08-01 00:00:00\n",
      "Entrenando con datos de: 2020-09-01 00:00:00\n",
      "Entrenando con datos de: 2020-10-01 00:00:00\n",
      "Entrenando con datos de: 2020-11-01 00:00:00\n",
      "Entrenando con datos de: 2020-12-01 00:00:00\n",
      "Revisa las carpetas dentro de 'LGBM_incremental_performance' para ver el desempeño de los modelos.\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de LightGBM\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "lgb_model = None\n",
    "folder_path = 'LGBM_incremental_performance'\n",
    "\n",
    "# Subcarpetas\n",
    "roc_folder = os.path.join(folder_path, 'roc_curves')\n",
    "conf_matrix_folder = os.path.join(folder_path, 'conf_matrices')\n",
    "metrics_folder = os.path.join(folder_path, 'metrics_texts')\n",
    "\n",
    "# Asegurarse de que las carpetas estén limpias\n",
    "for path in [folder_path, roc_folder, conf_matrix_folder, metrics_folder]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "metrics_file_path = os.path.join(metrics_folder, 'model_metrics.txt')\n",
    "with open(metrics_file_path, 'w') as metrics_file:\n",
    "    month_count = 0  # Contador para el reentrenamiento\n",
    "\n",
    "    # Iterar sobre cada segmento mensual\n",
    "    for name, month_data in monthly_datasets.items():\n",
    "        print(f\"Entrenando con datos de: {name}\")\n",
    "\n",
    "        # Dividir los datos en entrenamiento y validación\n",
    "        X = month_data.drop(['is_fraud'], axis=1)\n",
    "        y = month_data['is_fraud']\n",
    "        X_train_month, X_val_month, y_train_month, y_val_month = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        train_data_month = lgb.Dataset(X_train_month, label=y_train_month)\n",
    "        valid_data_month = lgb.Dataset(X_val_month, label=y_val_month)\n",
    "\n",
    "        # Reestablecer el modelo cada 3 meses\n",
    "        if month_count % 3 == 0:\n",
    "            lgb_model = None\n",
    "\n",
    "        # Entrenamiento con validación\n",
    "        lgb_model = lgb.train(\n",
    "            params,\n",
    "            train_data_month,\n",
    "            init_model=lgb_model,  # Utiliza el modelo anterior como base\n",
    "            num_boost_round=100,\n",
    "            valid_sets=[valid_data_month],\n",
    "            valid_names=['validation']\n",
    "        )\n",
    "\n",
    "        # Incrementar el contador de meses\n",
    "        month_count += 1\n",
    "\n",
    "        # Calcular métricas\n",
    "        y_pred = lgb_model.predict(X_val_month, num_iteration=lgb_model.best_iteration)\n",
    "        y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "        f1 = f1_score(y_val_month, y_pred_binary)\n",
    "        accuracy = accuracy_score(y_val_month, y_pred_binary)\n",
    "        precision = precision_score(y_val_month, y_pred_binary)\n",
    "        recall = recall_score(y_val_month, y_pred_binary)\n",
    "        cm = confusion_matrix(y_val_month, y_pred_binary)\n",
    "\n",
    "        # Graficar ROC\n",
    "        fpr, tpr, _ = roc_curve(y_val_month, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for {name.strftime(\"%B %Y\")}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(roc_folder, f'roc_curve_{name.strftime(\"%Y_%m\")}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Graficar matriz de confusión\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f'Confusion Matrix for {name.strftime(\"%B %Y\")}')\n",
    "        plt.savefig(os.path.join(conf_matrix_folder, f'conf_matrix_{name.strftime(\"%Y_%m\")}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Escribir métricas en el archivo\n",
    "        metrics_file.write(f\"Metrics for {name.strftime('%B %Y')}:\\n\")\n",
    "        metrics_file.write(f\"F1 Score: {f1:.2f}\\n\")\n",
    "        metrics_file.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "        metrics_file.write(f\"Precision: {precision:.2f}\\n\")\n",
    "        metrics_file.write(f\"Recall: {recall:.2f}\\n\")\n",
    "        metrics_file.write(f\"Confusion Matrix:\\n{cm}\\n\\n\")\n",
    "\n",
    "print(\"Revisa las carpetas dentro de 'LGBM_incremental_performance' para ver el desempeño de los modelos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
