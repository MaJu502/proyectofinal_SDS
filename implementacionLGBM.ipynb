{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos el dataset en el cual ya hemos trabajado las nuevas variables y caracteristicas.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "#!pip install --upgrade lightgbm\n",
    "#!pip install category_encoders\n",
    "#!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrimos los datasets de cada mes que ya hemos balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'final_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset para 2019-01 cargado desde: final_datasets\\resampled_data_2019_01.csv\n",
      "Dataset para 2019-02 cargado desde: final_datasets\\resampled_data_2019_02.csv\n",
      "Dataset para 2019-03 cargado desde: final_datasets\\resampled_data_2019_03.csv\n",
      "Dataset para 2019-04 cargado desde: final_datasets\\resampled_data_2019_04.csv\n",
      "Dataset para 2019-05 cargado desde: final_datasets\\resampled_data_2019_05.csv\n",
      "Dataset para 2019-06 cargado desde: final_datasets\\resampled_data_2019_06.csv\n",
      "Dataset para 2019-07 cargado desde: final_datasets\\resampled_data_2019_07.csv\n",
      "Dataset para 2019-08 cargado desde: final_datasets\\resampled_data_2019_08.csv\n",
      "Dataset para 2019-09 cargado desde: final_datasets\\resampled_data_2019_09.csv\n",
      "Dataset para 2019-10 cargado desde: final_datasets\\resampled_data_2019_10.csv\n",
      "Dataset para 2019-11 cargado desde: final_datasets\\resampled_data_2019_11.csv\n",
      "Dataset para 2019-12 cargado desde: final_datasets\\resampled_data_2019_12.csv\n",
      "Dataset para 2020-01 cargado desde: final_datasets\\resampled_data_2020_01.csv\n",
      "Dataset para 2020-02 cargado desde: final_datasets\\resampled_data_2020_02.csv\n",
      "Dataset para 2020-03 cargado desde: final_datasets\\resampled_data_2020_03.csv\n",
      "Dataset para 2020-04 cargado desde: final_datasets\\resampled_data_2020_04.csv\n",
      "Dataset para 2020-05 cargado desde: final_datasets\\resampled_data_2020_05.csv\n",
      "Dataset para 2020-06 cargado desde: final_datasets\\resampled_data_2020_06.csv\n",
      "Dataset para 2020-07 cargado desde: final_datasets\\resampled_data_2020_07.csv\n",
      "Dataset para 2020-08 cargado desde: final_datasets\\resampled_data_2020_08.csv\n",
      "Dataset para 2020-09 cargado desde: final_datasets\\resampled_data_2020_09.csv\n",
      "Dataset para 2020-10 cargado desde: final_datasets\\resampled_data_2020_10.csv\n",
      "Dataset para 2020-11 cargado desde: final_datasets\\resampled_data_2020_11.csv\n",
      "Dataset para 2020-12 cargado desde: final_datasets\\resampled_data_2020_12.csv\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los datasets\n",
    "monthly_datasets = {}\n",
    "\n",
    "# Listar todos los archivos en el directorio\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.startswith('resampled_data_') and file_name.endswith('.csv'):\n",
    "        # Construir el path completo del archivo\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "\n",
    "        # Extraer la fecha del nombre del archivo\n",
    "        date_str = file_name[len('resampled_data_'):-4]\n",
    "        month = pd.to_datetime(date_str, format='%Y_%m')\n",
    "\n",
    "        # Cargar el dataset\n",
    "        monthly_datasets[month] = pd.read_csv(file_path)\n",
    "        print(f\"Dataset para {month.strftime('%Y-%m')} cargado desde: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a separar el dataset en 80% entrenamiento y 20% validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento con LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento individual de los meses (no incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1f3c6f53d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no queremos llenar el output con imagenes entonces\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 425813, number of negative: 1289772\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.843345\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.123343\n",
      "[LightGBM] [Debug] init for col-wise cost 0.051941 seconds, init for row-wise cost 0.359326 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.499730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8520\n",
      "[LightGBM] [Info] Number of data points in the train set: 1715585, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248203 -> initscore=-1.108220\n",
      "[LightGBM] [Info] Start training from score -1.108220\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 22\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 25\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "Revisa las carpetas dentro de 'LGBM_combined_performance' para ver el desempeño del modelo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parámetros de LightGBM\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbose': 2\n",
    "}\n",
    "\n",
    "folder_path = 'LGBM_combined_performance'\n",
    "roc_folder = os.path.join(folder_path, 'roc_curves')\n",
    "conf_matrix_folder = os.path.join(folder_path, 'conf_matrices')\n",
    "metrics_folder = os.path.join(folder_path, 'metrics_texts')\n",
    "\n",
    "# Crear las carpetas si no existen\n",
    "for path in [folder_path, roc_folder, conf_matrix_folder, metrics_folder]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Unir todos los datasets en uno solo\n",
    "full_data = pd.concat(monthly_datasets.values())\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "X = full_data.drop(['is_fraud'], axis=1)\n",
    "y = full_data['is_fraud']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preparar los datasets para LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "# Entrenar el modelo\n",
    "lgb_model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=100,\n",
    "    valid_sets=[valid_data],\n",
    "    valid_names=['validation']\n",
    ")\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "y_pred = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Calcular métricas\n",
    "f1 = f1_score(y_val, y_pred_binary)\n",
    "accuracy = accuracy_score(y_val, y_pred_binary)\n",
    "precision = precision_score(y_val, y_pred_binary)\n",
    "recall = recall_score(y_val, y_pred_binary)\n",
    "cm = confusion_matrix(y_val, y_pred_binary)\n",
    "\n",
    "# Guardar métricas en un archivo\n",
    "metrics_file_path = os.path.join(metrics_folder, 'model_metrics.txt')\n",
    "with open(metrics_file_path, 'w') as metrics_file:\n",
    "    metrics_file.write(\"Combined Dataset Metrics:\\n\")\n",
    "    metrics_file.write(f\"F1 Score: {f1:.2f}\\n\")\n",
    "    metrics_file.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    metrics_file.write(f\"Precision: {precision:.2f}\\n\")\n",
    "    metrics_file.write(f\"Recall: {recall:.2f}\\n\")\n",
    "    metrics_file.write(f\"Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "# Graficar y guardar la curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Combined Dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(os.path.join(roc_folder, 'roc_curve_combined.png'))\n",
    "plt.close()\n",
    "\n",
    "# Graficar y guardar la matriz de confusión\n",
    "plt.figure(figsize=(6, 5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Combined Dataset')\n",
    "plt.savefig(os.path.join(conf_matrix_folder, 'conf_matrix_combined.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Revisa las carpetas dentro de 'LGBM_combined_performance' para ver el desempeño del modelo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con datos de: 2019-01-01 00:00:00\n",
      "Entrenando con datos de: 2019-02-01 00:00:00\n",
      "Entrenando con datos de: 2019-03-01 00:00:00\n",
      "Entrenando con datos de: 2019-04-01 00:00:00\n",
      "Entrenando con datos de: 2019-05-01 00:00:00\n",
      "Entrenando con datos de: 2019-06-01 00:00:00\n",
      "Entrenando con datos de: 2019-07-01 00:00:00\n",
      "Entrenando con datos de: 2019-08-01 00:00:00\n",
      "Entrenando con datos de: 2019-09-01 00:00:00\n",
      "Entrenando con datos de: 2019-10-01 00:00:00\n",
      "Entrenando con datos de: 2019-11-01 00:00:00\n",
      "Entrenando con datos de: 2019-12-01 00:00:00\n",
      "Entrenando con datos de: 2020-01-01 00:00:00\n",
      "Entrenando con datos de: 2020-02-01 00:00:00\n",
      "Entrenando con datos de: 2020-03-01 00:00:00\n",
      "Entrenando con datos de: 2020-04-01 00:00:00\n",
      "Entrenando con datos de: 2020-05-01 00:00:00\n",
      "Entrenando con datos de: 2020-06-01 00:00:00\n",
      "Entrenando con datos de: 2020-07-01 00:00:00\n",
      "Entrenando con datos de: 2020-08-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con datos de: 2020-09-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_59880\\103104873.py:68: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n",
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_59880\\103104873.py:81: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(6, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con datos de: 2020-10-01 00:00:00\n",
      "Entrenando con datos de: 2020-11-01 00:00:00\n",
      "Entrenando con datos de: 2020-12-01 00:00:00\n",
      "Revisa las carpetas dentro de 'LGBM_incremental_performance' para ver el desempeño de los modelos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parámetros de LightGBM\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "lgb_model = None\n",
    "folder_path = 'LGBM_incremental_performance'\n",
    "\n",
    "# Subcarpetas\n",
    "roc_folder = os.path.join(folder_path, 'roc_curves')\n",
    "conf_matrix_folder = os.path.join(folder_path, 'conf_matrices')\n",
    "metrics_folder = os.path.join(folder_path, 'metrics_texts')\n",
    "\n",
    "# Asegurarse de que las carpetas estén limpias\n",
    "for path in [folder_path, roc_folder, conf_matrix_folder, metrics_folder]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "metrics_file_path = os.path.join(metrics_folder, 'model_metrics.txt')\n",
    "with open(metrics_file_path, 'w') as metrics_file:\n",
    "    month_count = 0  # Contador para el reentrenamiento\n",
    "\n",
    "    # Iterar sobre cada segmento mensual\n",
    "    for name, month_data in monthly_datasets.items():\n",
    "        print(f\"Entrenando con datos de: {name}\")\n",
    "\n",
    "        # Dividir los datos en entrenamiento y validación\n",
    "        X = month_data.drop(['is_fraud'], axis=1)\n",
    "        y = month_data['is_fraud']\n",
    "        X_train_month, X_val_month, y_train_month, y_val_month = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        train_data_month = lgb.Dataset(X_train_month, label=y_train_month)\n",
    "        valid_data_month = lgb.Dataset(X_val_month, label=y_val_month)\n",
    "\n",
    "        # Reestablecer el modelo cada 3 meses\n",
    "        if month_count % 3 == 0:\n",
    "            lgb_model = None\n",
    "\n",
    "        # Entrenamiento con validación\n",
    "        lgb_model = lgb.train(\n",
    "            params,\n",
    "            train_data_month,\n",
    "            init_model=lgb_model,  # Utiliza el modelo anterior como base\n",
    "            num_boost_round=100,\n",
    "            valid_sets=[valid_data_month],\n",
    "            valid_names=['validation']\n",
    "        )\n",
    "\n",
    "        # Incrementar el contador de meses\n",
    "        month_count += 1\n",
    "\n",
    "        # Calcular métricas\n",
    "        y_pred = lgb_model.predict(X_val_month, num_iteration=lgb_model.best_iteration)\n",
    "        y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "        f1 = f1_score(y_val_month, y_pred_binary)\n",
    "        accuracy = accuracy_score(y_val_month, y_pred_binary)\n",
    "        precision = precision_score(y_val_month, y_pred_binary)\n",
    "        recall = recall_score(y_val_month, y_pred_binary)\n",
    "        cm = confusion_matrix(y_val_month, y_pred_binary)\n",
    "\n",
    "        # Graficar ROC\n",
    "        fpr, tpr, _ = roc_curve(y_val_month, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for {name.strftime(\"%B %Y\")}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(roc_folder, f'roc_curve_{name.strftime(\"%Y_%m\")}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Graficar matriz de confusión\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f'Confusion Matrix for {name.strftime(\"%B %Y\")}')\n",
    "        plt.savefig(os.path.join(conf_matrix_folder, f'conf_matrix_{name.strftime(\"%Y_%m\")}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Escribir métricas en el archivo\n",
    "        metrics_file.write(f\"Metrics for {name.strftime('%B %Y')}:\\n\")\n",
    "        metrics_file.write(f\"F1 Score: {f1:.2f}\\n\")\n",
    "        metrics_file.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "        metrics_file.write(f\"Precision: {precision:.2f}\\n\")\n",
    "        metrics_file.write(f\"Recall: {recall:.2f}\\n\")\n",
    "        metrics_file.write(f\"Confusion Matrix:\\n{cm}\\n\\n\")\n",
    "\n",
    "print(\"Revisa las carpetas dentro de 'LGBM_incremental_performance' para ver el desempeño de los modelos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
